/**
 * ODAVL Autopilot - Integration Tests
 * 
 * Tests the full OBSERVEâ†’DECIDEâ†’ACTâ†’VERIFYâ†’LEARN loop
 * with 5 key scenarios:
 * 
 * 1. Happy Path - Full success cycle
 * 2. No Issues - Noop handling when codebase is clean
 * 3. No Recipes - Noop when no recipes match metrics
 * 4. Gates Fail - Rollback when quality gates fail
 * 5. Blacklist - Recipe blacklisting after 3 consecutive failures
 */

import { describe, it, expect, beforeEach, beforeAll, afterAll } from 'vitest';
import { observe } from '../../odavl-studio/autopilot/engine/src/phases/observe';
import { decide } from '../../odavl-studio/autopilot/engine/src/phases/decide';
import { act } from '../../odavl-studio/autopilot/engine/src/phases/act';
import { verify } from '../../odavl-studio/autopilot/engine/src/phases/verify';
import { learn } from '../../odavl-studio/autopilot/engine/src/phases/learn';
import fs from 'node:fs';
import path from 'node:path';

const FIXTURES_DIR = path.resolve(__dirname, '../fixtures/sample-codebase');
const ODAVL_DIR = path.resolve(FIXTURES_DIR, '.odavl');
const RECIPES_TRUST_PATH = path.join(ODAVL_DIR, 'recipes-trust.json');

describe('ODAVL Autopilot - Full Loop Integration', () => {
    beforeAll(() => {
        // Setup: Create .odavl directory structure for test fixtures
        if (!fs.existsSync(ODAVL_DIR)) {
            fs.mkdirSync(ODAVL_DIR, { recursive: true });
        }

        // Create subdirectories
        for (const dir of ['recipes', 'undo', 'ledger', 'metrics', 'attestation']) {
            const dirPath = path.join(ODAVL_DIR, dir);
            if (!fs.existsSync(dirPath)) {
                fs.mkdirSync(dirPath, { recursive: true });
            }
        }

        // Create gates.yml for test fixtures
        const gatesContent = `eslint:
  deltaMax: 0
typeErrors:
  deltaMax: 0
testCoverage:
  minPercentage: 80
  deltaMax: -2
complexity:
  maxPerFunction: 15
thresholds:
  min_success_rate: 0.75
  max_consecutive_failures: 3
`;
        fs.writeFileSync(path.join(ODAVL_DIR, 'gates.yml'), gatesContent, 'utf-8');

        console.log('âœ… Test fixtures setup complete');
    });

    beforeEach(() => {
        // Reset recipes-trust.json before each test to avoid state pollution
        if (fs.existsSync(RECIPES_TRUST_PATH)) {
            fs.unlinkSync(RECIPES_TRUST_PATH);
        }
    });

    afterAll(() => {
        // Cleanup: Remove test artifacts
        if (fs.existsSync(ODAVL_DIR)) {
            fs.rmSync(ODAVL_DIR, { recursive: true, force: true });
        }
        console.log('âœ… Test cleanup complete');
    });

    describe('Scenario 1: Happy Path - Full Success Cycle', () => {
        it('should complete full ODAVL loop successfully', async () => {
            console.log('\nðŸ§ª Testing Happy Path...');

            // Step 1: OBSERVE - Detect issues
            console.log('  1ï¸âƒ£ OBSERVE Phase...');
            const beforeMetrics = await observe(FIXTURES_DIR);

            expect(beforeMetrics).toBeDefined();
            expect(beforeMetrics.totalIssues).toBeGreaterThan(0);
            console.log(`    âœ… Detected ${beforeMetrics.totalIssues} issues`);

            // Step 2: DECIDE - Select recipe
            console.log('  2ï¸âƒ£ DECIDE Phase...');
            const decision = await decide(beforeMetrics);

            expect(decision).toBeDefined();
            // May be noop if no recipes match the specific metrics from fixtures
            console.log(`    âœ… Decision: ${decision}`);
            if (decision === 'noop') {
                console.log('    â„¹ï¸  No recipes matched - skipping ACT/VERIFY');
                return;
            }

            // Step 3: ACT - Execute recipe
            console.log('  3ï¸âƒ£ ACT Phase...');
            const actResult = await act(decision);

            expect(actResult).toBeDefined();
            expect(actResult.success).toBe(true);
            expect(actResult.actionsExecuted).toBeGreaterThan(0);
            console.log(`    âœ… Executed ${actResult.actionsExecuted} actions`);

            // Step 4: VERIFY - Check improvements
            console.log('  4ï¸âƒ£ VERIFY Phase...');
            const verifyResult = await verify(beforeMetrics, decision, FIXTURES_DIR);

            expect(verifyResult).toBeDefined();
            expect(verifyResult.after).toBeDefined();
            expect(verifyResult.gatesPassed).toBe(true);

            const improvement = beforeMetrics.totalIssues - verifyResult.after.totalIssues;
            console.log(`    âœ… Improvement: ${improvement} issues fixed`);

            // Step 5: LEARN - Update trust scores
            console.log('  5ï¸âƒ£ LEARN Phase...');
            const learnResult = await learn(
                decision,
                verifyResult.gatesPassed,
                {
                    eslint: verifyResult.deltas.eslint,
                    typescript: verifyResult.deltas.types,
                    total: improvement
                },
                verifyResult.attestation?.hash
            );

            expect(learnResult).toBeDefined();
            expect(learnResult.trustUpdated).toBe(true);
            // Trust starts at 0.5 (default), success increases to 1.0 (max)
            expect(learnResult.newTrust).toBeGreaterThanOrEqual(learnResult.oldTrust || 0);
            expect(learnResult.newTrust).toBeGreaterThan(0.5); // Should increase from default
            console.log(`    âœ… Trust updated: ${learnResult.oldTrust?.toFixed(2)} â†’ ${learnResult.newTrust.toFixed(2)}`);

            console.log('  âœ… Happy Path Complete!\n');
        }, 180000); // 3 minutes timeout for VERIFY phase
    });

    describe('Scenario 2: No Issues - Noop Handling', () => {
        it('should return noop when no issues detected', async () => {
            console.log('\nðŸ§ª Testing No Issues Scenario...');

            // Mock metrics with zero issues
            const cleanMetrics = {
                typescript: 0,
                eslint: 0,
                security: 0,
                performance: 0,
                imports: 0,
                packages: 0,
                runtime: 0,
                build: 0,
                circular: 0,
                network: 0,
                complexity: 0,
                isolation: 0,
                totalIssues: 0
            };

            console.log('  1ï¸âƒ£ OBSERVE Phase (mocked clean codebase)...');
            console.log(`    âœ… Detected 0 issues`);

            console.log('  2ï¸âƒ£ DECIDE Phase...');
            const fullCleanMetrics = {
                ...cleanMetrics,
                timestamp: new Date().toISOString(),
                runId: 'test-noop',
                targetDir: FIXTURES_DIR
            };
            const decision = await decide(fullCleanMetrics);

            expect(decision).toBe('noop');
            console.log(`    âœ… Decision: noop (no issues to fix)`);

            console.log('  âœ… No Issues Scenario Complete!\n');
        });
    });

    describe('Scenario 3: No Matching Recipes', () => {
        it('should return noop when no recipes match metrics', async () => {
            console.log('\nðŸ§ª Testing No Matching Recipes...');

            // Mock metrics that won't match any recipe conditions
            const unmatchedMetrics = {
                typescript: 0,
                eslint: 0,
                security: 0,
                performance: 0,
                imports: 1, // Below threshold (recipes require > 5)
                packages: 0,
                runtime: 0,
                build: 0,
                circular: 0,
                network: 0,
                complexity: 0,
                isolation: 0,
                totalIssues: 1
            };

            console.log('  1ï¸âƒ£ OBSERVE Phase (mocked)...');
            console.log(`    âœ… Detected ${unmatchedMetrics.totalIssues} issue (below recipe thresholds)`);

            console.log('  2ï¸âƒ£ DECIDE Phase...');
            const fullUnmatchedMetrics = {
                ...unmatchedMetrics,
                timestamp: new Date().toISOString(),
                runId: 'test-nomatch',
                targetDir: FIXTURES_DIR
            };
            const decision = await decide(fullUnmatchedMetrics);

            expect(decision).toBe('noop');
            console.log(`    âœ… Decision: noop (no recipes match)`);

            console.log('  âœ… No Matching Recipes Scenario Complete!\n');
        });
    });

    describe('Scenario 4: Gates Fail - Rollback', () => {
        it('should rollback when quality gates fail', async () => {
            console.log('\nðŸ§ª Testing Gates Fail Scenario...');

            // This test requires mocking a recipe that makes things worse
            // For now, we'll test the verify phase with degraded metrics

            const beforeMetrics = {
                typescript: 5,
                eslint: 10,
                security: 0,
                performance: 0,
                imports: 0,
                packages: 0,
                runtime: 0,
                build: 0,
                circular: 0,
                network: 0,
                complexity: 0,
                isolation: 0,
                totalIssues: 15
            };

            // Mock "after" metrics showing regression
            const afterMetrics = {
                ...beforeMetrics,
                typescript: 10, // Increased (gates should fail)
                eslint: 15, // Increased (gates should fail)
                totalIssues: 25
            };

            console.log('  1ï¸âƒ£ Before metrics: 15 issues');
            console.log('  2ï¸âƒ£ After metrics: 25 issues (regression!)');
            console.log('  3ï¸âƒ£ VERIFY Phase...');

            // Note: We need to mock the verify function to test this properly
            // For now, we're checking the delta calculation logic

            const eslintDelta = afterMetrics.eslint - beforeMetrics.eslint;
            const typesDelta = afterMetrics.typescript - beforeMetrics.typescript;

            expect(eslintDelta).toBeGreaterThan(0); // Regression
            expect(typesDelta).toBeGreaterThan(0); // Regression

            console.log(`    âŒ ESLint delta: +${eslintDelta} (gate: deltaMax 0)`);
            console.log(`    âŒ TypeScript delta: +${typesDelta} (gate: deltaMax 0)`);
            console.log('    âœ… Gates would fail - rollback triggered');

            console.log('  âœ… Gates Fail Scenario Complete!\n');
        });
    });

    describe('Scenario 5: Blacklist - 3 Consecutive Failures', () => {
        it('should blacklist recipe after 3 consecutive failures', async () => {
            console.log('\nðŸ§ª Testing Blacklist Scenario...');

            // Use unique recipe ID to avoid state pollution
            const testRecipeId = `test-failing-recipe-${Date.now()}`;

            // Simulate 3 consecutive failures
            console.log('  Simulating 3 consecutive failures...');

            let learnResult1 = await learn(testRecipeId, false);
            expect(learnResult1.trustUpdated).toBe(true);
            expect(learnResult1.blacklisted).toBe(false);
            console.log(`    1ï¸âƒ£ Failure 1: trust = ${learnResult1.newTrust.toFixed(2)}, blacklisted = false`);

            let learnResult2 = await learn(testRecipeId, false);
            expect(learnResult2.trustUpdated).toBe(true);
            expect(learnResult2.blacklisted).toBe(false);
            console.log(`    2ï¸âƒ£ Failure 2: trust = ${learnResult2.newTrust.toFixed(2)}, blacklisted = false`);

            let learnResult3 = await learn(testRecipeId, false);
            expect(learnResult3.trustUpdated).toBe(true);
            expect(learnResult3.blacklisted).toBe(true);
            console.log(`    3ï¸âƒ£ Failure 3: trust = ${learnResult3.newTrust.toFixed(2)}, blacklisted = true âœ…`);

            console.log('  âœ… Blacklist Scenario Complete!\n');
        });
    });

    describe('Performance Tests', () => {
        it('should complete full loop in under 60 seconds', async () => {
            console.log('\nðŸ§ª Testing Performance...');

            const startTime = Date.now();

            const beforeMetrics = await observe(FIXTURES_DIR);
            const decision = await decide(beforeMetrics);

            if (decision !== 'noop') {
                await act(decision);
                await verify(beforeMetrics, decision, FIXTURES_DIR);
            }

            const duration = Date.now() - startTime;

            expect(duration).toBeLessThan(60000); // 60 seconds
            console.log(`  âœ… Full loop completed in ${(duration / 1000).toFixed(2)}s`);
            console.log(`  âœ… Performance Test Complete!\n`);
        }, 180000); // 3 minutes timeout for VERIFY phase
    });
});
