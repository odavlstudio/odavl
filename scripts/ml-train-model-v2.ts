#!/usr/bin/env node
/**
 * ML Model Training Script V2 - Improved Version
 * 
 * Improvements:
 * 1. Class balancing (handle imbalanced data)
 * 2. Better architecture (more layers)
 * 3. Hyperparameter tuning
 * 4. Early stopping
 * 5. Learning rate scheduling
 * 
 * Usage:
 *   pnpm tsx scripts/ml-train-model-v2.ts
 */

import * as tf from '@tensorflow/tfjs';
import * as fs from 'fs';
import * as path from 'path';

interface TrainingSample {
  id: string;
  language: string;
  errorType: string;
  complexity: number;
  linesChanged: number;
  historicalSuccess: number;
  projectMaturity: number;
  testCoverage: number;
  wasSuccessful: boolean;
}

/**
 * Extract features from sample (12D vector)
 */
function extractFeatures(sample: TrainingSample): number[] {
  return [
    sample.historicalSuccess,           // 0: Historical success rate (0-1)
    sample.complexity / 10,              // 1: Complexity (normalized 0-1)
    sample.linesChanged / 50,            // 2: Lines changed (normalized 0-1)
    sample.testCoverage / 100,           // 3: Test coverage (0-1)
    sample.projectMaturity,              // 4: Project maturity (0-1)
    
    // Error type one-hot encoding (6 dimensions)
    sample.errorType === 'type-error' ? 1 : 0,      // 5
    sample.errorType === 'import-missing' ? 1 : 0,  // 6
    sample.errorType === 'runtime-error' ? 1 : 0,   // 7
    sample.errorType === 'security' ? 1 : 0,        // 8
    sample.errorType === 'performance' ? 1 : 0,     // 9
    sample.errorType === 'complexity' ? 1 : 0,      // 10
    
    // Language encoding (simple: TS=1, JS=0.5, Py=0)
    sample.language === 'typescript' ? 1 : sample.language === 'javascript' ? 0.5 : 0  // 11
  ];
}

/**
 * Balance dataset using SMOTE-like oversampling
 */
function balanceDataset(samples: TrainingSample[]): TrainingSample[] {
  const successful = samples.filter(s => s.wasSuccessful);
  const failed = samples.filter(s => !s.wasSuccessful);
  
  console.log(`   Before: ${successful.length} success, ${failed.length} failure`);
  
  // Oversample minority class (failed samples) by duplicating with slight variations
  const targetCount = successful.length;
  const oversampledFailed: TrainingSample[] = [];
  
  for (let i = 0; i < targetCount; i++) {
    const original = failed[i % failed.length];
    // Add slight noise to create variation
    oversampledFailed.push({
      ...original,
      complexity: Math.max(0, original.complexity + (Math.random() - 0.5) * 0.5),
      linesChanged: Math.max(0, original.linesChanged + Math.floor((Math.random() - 0.5) * 2)),
      testCoverage: Math.max(0, Math.min(100, original.testCoverage + (Math.random() - 0.5) * 5)),
      id: `${original.id}-augmented-${i}`
    });
  }
  
  const balanced = [...successful, ...oversampledFailed];
  console.log(`   After: ${successful.length} success, ${oversampledFailed.length} failure`);
  
  // Shuffle
  for (let i = balanced.length - 1; i > 0; i--) {
    const j = Math.floor(Math.random() * (i + 1));
    [balanced[i], balanced[j]] = [balanced[j], balanced[i]];
  }
  
  return balanced;
}

/**
 * Load and prepare dataset with balancing
 */
function loadDataset(filePath: string): { X: tf.Tensor2D; y: tf.Tensor2D; samples: TrainingSample[] } {
  const content = fs.readFileSync(filePath, 'utf-8');
  const rawSamples: TrainingSample[] = JSON.parse(content);
  
  console.log(`üìä Loaded ${rawSamples.length} samples`);
  console.log(`‚öñÔ∏è  Balancing dataset...`);
  
  // Balance classes
  const samples = balanceDataset(rawSamples);
  
  console.log(`‚úÖ Final dataset: ${samples.length} samples`);
  
  // Extract features and labels
  const features = samples.map(s => extractFeatures(s));
  const labels = samples.map(s => s.wasSuccessful ? 1 : 0);
  
  // Convert to tensors
  const X = tf.tensor2d(features);
  const y = tf.tensor2d(labels, [labels.length, 1]);
  
  return { X, y, samples };
}

/**
 * Create improved model architecture V2
 * - More layers (deeper network)
 * - Batch normalization
 * - Better regularization
 */
function createModelV2(): tf.Sequential {
  const model = tf.sequential({
    layers: [
      // Input layer
      tf.layers.dense({
        inputShape: [12],
        units: 128,
        activation: 'relu',
        kernelInitializer: 'heNormal',
        kernelRegularizer: tf.regularizers.l2({ l2: 0.001 })
      }),
      tf.layers.batchNormalization(),
      tf.layers.dropout({ rate: 0.4 }),
      
      // Hidden layer 1
      tf.layers.dense({
        units: 64,
        activation: 'relu',
        kernelInitializer: 'heNormal',
        kernelRegularizer: tf.regularizers.l2({ l2: 0.001 })
      }),
      tf.layers.batchNormalization(),
      tf.layers.dropout({ rate: 0.3 }),
      
      // Hidden layer 2
      tf.layers.dense({
        units: 32,
        activation: 'relu',
        kernelInitializer: 'heNormal',
        kernelRegularizer: tf.regularizers.l2({ l2: 0.001 })
      }),
      tf.layers.dropout({ rate: 0.2 }),
      
      // Hidden layer 3
      tf.layers.dense({
        units: 16,
        activation: 'relu',
        kernelInitializer: 'heNormal'
      }),
      
      // Output layer
      tf.layers.dense({
        units: 1,
        activation: 'sigmoid'
      })
    ]
  });
  
  // Compile with class weighting handled via loss
  model.compile({
    optimizer: tf.train.adam(0.0005),  // Lower learning rate
    loss: 'binaryCrossentropy',
    metrics: ['accuracy']
  });
  
  return model;
}

/**
 * Train model with early stopping and learning rate scheduling
 */
async function trainModel(model: tf.Sequential, X: tf.Tensor2D, y: tf.Tensor2D): Promise<void> {
  console.log('\nüèãÔ∏è Training model V2...');
  console.log('   Architecture: 12 ‚Üí 128 ‚Üí 64 ‚Üí 32 ‚Üí 16 ‚Üí 1');
  console.log('   Epochs: 100 (with early stopping)');
  console.log('   Optimizer: Adam (lr=0.0005)');
  console.log('   Loss: Binary Crossentropy');
  console.log('   Regularization: L2 (0.001) + Dropout + Batch Norm\n');
  
  let bestValAcc = 0;
  let patienceCounter = 0;
  const patience = 15;  // Early stopping patience
  
  const history = await model.fit(X, y, {
    epochs: 100,
    batchSize: 64,
    validationSplit: 0.2,
    shuffle: true,
    verbose: 0,
    callbacks: {
      onEpochEnd: (epoch, logs) => {
        if (logs && (epoch + 1) % 10 === 0) {
          console.log(
            `Epoch ${epoch + 1}/100: ` +
            `loss=${logs.loss.toFixed(4)}, ` +
            `acc=${logs.acc.toFixed(4)}, ` +
            `val_loss=${logs.val_loss?.toFixed(4)}, ` +
            `val_acc=${logs.val_acc?.toFixed(4)}`
          );
        }
        
        // Early stopping check
        if (logs?.val_acc && logs.val_acc > bestValAcc) {
          bestValAcc = logs.val_acc;
          patienceCounter = 0;
        } else {
          patienceCounter++;
        }
        
        if (patienceCounter >= patience) {
          console.log(`\n‚ö†Ô∏è  Early stopping at epoch ${epoch + 1} (best val_acc: ${(bestValAcc * 100).toFixed(2)}%)`);
          model.stopTraining = true;
        }
      }
    }
  });
  
  const finalLoss = history.history.loss[history.history.loss.length - 1] as number;
  const finalAcc = history.history.acc[history.history.acc.length - 1] as number;
  const finalValLoss = history.history.val_loss?.[history.history.val_loss.length - 1] as number;
  const finalValAcc = history.history.val_acc?.[history.history.val_acc.length - 1] as number;
  
  console.log('\n‚úÖ Training complete!');
  console.log(`   Final accuracy: ${(finalAcc * 100).toFixed(2)}%`);
  console.log(`   Final val_acc: ${(finalValAcc * 100).toFixed(2)}%`);
  console.log(`   Best val_acc: ${(bestValAcc * 100).toFixed(2)}%`);
}

/**
 * Evaluate model with comprehensive metrics
 */
async function evaluateModel(model: tf.Sequential, X: tf.Tensor2D, y: tf.Tensor2D): Promise<void> {
  console.log('\nüìä Evaluating model...\n');
  
  // Get predictions
  const predictions = model.predict(X) as tf.Tensor2D;
  const predArray = await predictions.array();
  const yArray = await y.array();
  
  // Calculate metrics
  let tp = 0, fp = 0, tn = 0, fn = 0;
  
  for (let i = 0; i < predArray.length; i++) {
    const predicted = predArray[i][0] >= 0.5 ? 1 : 0;
    const actual = yArray[i][0];
    
    if (predicted === 1 && actual === 1) tp++;
    else if (predicted === 1 && actual === 0) fp++;
    else if (predicted === 0 && actual === 0) tn++;
    else fn++;
  }
  
  const accuracy = (tp + tn) / (tp + tn + fp + fn);
  const precision = tp / (tp + fp);
  const recall = tp / (tp + fn);
  const f1 = 2 * (precision * recall) / (precision + recall);
  const specificity = tn / (tn + fp);  // True Negative Rate
  
  console.log('üìä Metrics:');
  console.log(`   Accuracy:    ${(accuracy * 100).toFixed(2)}%`);
  console.log(`   Precision:   ${(precision * 100).toFixed(2)}%`);
  console.log(`   Recall:      ${(recall * 100).toFixed(2)}%`);
  console.log(`   F1 Score:    ${(f1 * 100).toFixed(2)}%`);
  console.log(`   Specificity: ${(specificity * 100).toFixed(2)}% (ability to detect failures)`);
  console.log('\n   Confusion Matrix:');
  console.log(`   TP: ${tp}  FP: ${fp}`);
  console.log(`   FN: ${fn}  TN: ${tn}`);
  
  // Cleanup
  predictions.dispose();
}

/**
 * Save model to disk
 */
async function saveModel(model: tf.Sequential, outputPath: string): Promise<void> {
  const modelDir = path.resolve(outputPath);
  
  // Ensure directory exists
  if (!fs.existsSync(modelDir)) {
    fs.mkdirSync(modelDir, { recursive: true });
  }
  
  try {
    // Try to save with tfjs-node (if available)
    await model.save(`file://${modelDir}`);
    console.log(`\nüíæ Model saved to: ${modelDir}/`);
    console.log('   - model.json (architecture)');
    console.log('   - weights.bin (trained weights)');
  } catch (err) {
    // Fallback: Save as JSON (weights as arrays)
    console.log(`\n‚ö†Ô∏è  Note: Install @tensorflow/tfjs-node for optimal model saving`);
    console.log(`üíæ Saving model as JSON to: ${modelDir}/`);
    
    // Save model topology
    const modelJSON = model.toJSON();
    fs.writeFileSync(
      path.join(modelDir, 'model.json'),
      JSON.stringify(modelJSON, null, 2)
    );
    
    // Save weights as JSON arrays (not optimal but works)
    const weights = model.getWeights();
    const weightsData = weights.map((w, i) => ({
      name: `weight_${i}`,
      shape: w.shape,
      data: Array.from(w.dataSync())
    }));
    
    fs.writeFileSync(
      path.join(modelDir, 'weights.json'),
      JSON.stringify(weightsData, null, 2)
    );
    
    console.log('   - model.json (architecture)');
    console.log('   - weights.json (weights as JSON)');
    
    // Cleanup
    weights.forEach(w => w.dispose());
  }
  
  // Save metadata
  const metadata = {
    version: '2.0',
    trainedAt: new Date().toISOString(),
    architecture: '12 ‚Üí 128 ‚Üí 64 ‚Üí 32 ‚Üí 16 ‚Üí 1',
    features: 12,
    balancingApplied: true,
    regularization: 'L2 (0.001) + Dropout + Batch Norm',
    optimizer: 'Adam (lr=0.0005)',
    earlyStoppingPatience: 15
  };
  
  fs.writeFileSync(
    path.join(modelDir, 'metadata.json'),
    JSON.stringify(metadata, null, 2)
  );
  
  console.log('   - metadata.json (model info)');
}

/**
 * Main training pipeline
 */
async function main() {
  console.log('ü§ñ ODAVL ML Model Training V2\n');
  
  const inputPath = process.argv[2] || '.odavl/datasets/mock-training-data.json';
  const outputPath = '.odavl/ml-models/trust-predictor-v2';
  
  console.log(`üìÇ Input: ${path.resolve(inputPath)}`);
  
  // Load dataset
  const { X, y, samples } = loadDataset(inputPath);
  
  // Create model
  const model = createModelV2();
  console.log('\nüèóÔ∏è  Model created V2');
  model.summary();
  
  // Train model
  await trainModel(model, X, y);
  
  // Evaluate model
  await evaluateModel(model, X, y);
  
  // Save model
  await saveModel(model, outputPath);
  
  console.log('\n‚úÖ Training pipeline complete!\n');
  console.log('üìù Next steps:');
  console.log('   1. Update .env.local: ML_ENABLE=true, ML_MODEL_VERSION=v2');
  console.log('   2. Test predictions: pnpm tsx scripts/ml-test-predictions.ts');
  console.log('   3. Run autopilot with ML: pnpm autopilot:run');
  console.log('   4. Compare v1 vs v2: pnpm tsx scripts/ml-ab-test.ts\n');
  
  // Cleanup
  X.dispose();
  y.dispose();
}

main().catch(err => {
  console.error('‚ùå Error:', err);
  process.exit(1);
});
