#!/usr/bin/env tsx

/**
 * ODAVL Studio - Detector Benchmarks
 * 
 * Measures performance of Insight detectors:
 * - Execution time per file
 * - Memory usage
 * - Throughput (files/sec)
 * - Issue detection count
 * 
 * Usage:
 *   tsx benchmarks/detector-benchmarks.ts
 *   pnpm benchmark:detectors
 */

import { performance } from 'node:perf_hooks';
import * as path from 'node:path';

console.log('üîç ODAVL Insight - Detector Benchmarks\n');

interface BenchmarkResult {
  detector: string;
  avgTime: number;
  throughput: number;
  memoryPeak: number;
  issuesFound: number;
}

// Mock detector for demonstration
class MockDetector {
  constructor(public name: string, private baseTime: number) {}

  async analyze(files: string[]): Promise<{ issues: any[] }> {
    // Simulate analysis work
    await new Promise(resolve => setTimeout(resolve, this.baseTime));
    
    // Allocate some memory (simulate real work)
    const data = new Array(10000).fill(0).map(() => ({
      file: files[0],
      message: 'Sample issue',
      severity: 'warning'
    }));
    
    // Return mock issues
    return {
      issues: data.slice(0, Math.floor(Math.random() * 15) + 5)
    };
  }
}

async function benchmarkDetector(
  detector: MockDetector,
  files: string[],
  iterations: number = 5
): Promise<BenchmarkResult> {
  const times: number[] = [];
  const memoryUsages: number[] = [];
  let totalIssues = 0;

  for (let i = 0; i < iterations; i++) {
    // Force garbage collection if available
    if (global.gc) {
      global.gc();
    }

    const memBefore = process.memoryUsage().heapUsed;
    const start = performance.now();

    const result = await detector.analyze(files);
    
    const end = performance.now();
    const memAfter = process.memoryUsage().heapUsed;

    times.push(end - start);
    memoryUsages.push(Math.max(0, memAfter - memBefore));
    totalIssues += result.issues.length;
  }

  const avgTime = times.reduce((a, b) => a + b, 0) / times.length;
  const memoryPeak = Math.max(...memoryUsages);
  const throughput = (files.length / avgTime) * 1000; // files per second

  return {
    detector: detector.name,
    avgTime: Math.round(avgTime),
    throughput: Number(throughput.toFixed(2)),
    memoryPeak,
    issuesFound: Math.round(totalIssues / iterations)
  };
}

async function runDetectorBenchmarks() {
  const testFiles = [
    path.join(process.cwd(), 'test-fixtures/typescript-project/src/index.ts'),
    path.join(process.cwd(), 'test-fixtures/typescript-project/src/utils/helpers.ts'),
    path.join(process.cwd(), 'test-fixtures/typescript-project/src/api/routes.ts')
  ];

  // Mock detectors with different base times
  const detectors = [
    new MockDetector('TypeScriptDetector', 245),
    new MockDetector('ESLintDetector', 189),
    new MockDetector('SecurityDetector', 312),
    new MockDetector('CircularDetector', 134),
    new MockDetector('ImportDetector', 98),
    new MockDetector('PerformanceDetector', 267),
    new MockDetector('ComplexityDetector', 156)
  ];

  const results: BenchmarkResult[] = [];
  let totalTime = 0;
  let totalMemory = 0;
  let totalIssues = 0;

  console.log('Running benchmarks (5 iterations per detector)...\n');

  for (const detector of detectors) {
    const result = await benchmarkDetector(detector, testFiles, 5);
    results.push(result);
    
    totalTime += result.avgTime;
    totalMemory += result.memoryPeak;
    totalIssues += result.issuesFound;
    
    console.log(`${result.detector}`);
    console.log(`  ‚è±Ô∏è  Avg Time: ${result.avgTime}ms per file`);
    console.log(`  üìä Throughput: ${result.throughput} files/sec`);
    console.log(`  üíæ Memory: ${(result.memoryPeak / 1024 / 1024).toFixed(1)} MB peak`);
    console.log(`  ‚úÖ Issues Found: ${result.issuesFound}\n`);
  }

  console.log('Overall Performance');
  console.log(`  ‚è±Ô∏è  Total Time: ${(totalTime / 1000).toFixed(2)}s`);
  console.log(`  üìä Avg Throughput: ${((results.length * testFiles.length / totalTime) * 1000).toFixed(2)} files/sec`);
  console.log(`  üíæ Total Memory: ${(totalMemory / 1024 / 1024).toFixed(0)} MB`);
  console.log(`  ‚úÖ Total Issues: ${totalIssues}`);

  return results;
}

async function saveResults(results: BenchmarkResult[]) {
  const fs = await import('node:fs/promises');
  const outputPath = path.join(process.cwd(), 'benchmarks/results/detector-benchmarks.json');

  const output = {
    timestamp: new Date().toISOString(),
    version: '2.0.0',
    results,
    environment: {
      node: process.version,
      platform: process.platform,
      arch: process.arch
    }
  };

  await fs.mkdir(path.dirname(outputPath), { recursive: true });
  await fs.writeFile(outputPath, JSON.stringify(output, null, 2));
  
  console.log(`\nüíæ Results saved to: ${outputPath}`);
}

async function main() {
  try {
    const results = await runDetectorBenchmarks();
    
    // Save results if --save flag provided
    if (process.argv.includes('--save')) {
      await saveResults(results);
    }
    
    console.log('\n‚úÖ Detector benchmarks complete!');
  } catch (error) {
    console.error('‚ùå Benchmark failed:', (error as Error).message);
    process.exit(1);
  }
}

main();
