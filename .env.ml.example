# ====================================
# ODAVL ML System V2 - Environment Configuration
# ====================================

# -------------------------------------
# GitHub API Configuration
# -------------------------------------
# Get token at: https://github.com/settings/tokens
# Required scope: public_repo (read-only)
# Without token: 60 requests/hour
# With token: 5,000 requests/hour
GITHUB_TOKEN=ghp_replace_with_your_token_32_characters

# -------------------------------------
# ML Feature Flags
# -------------------------------------
# Enable ML trust scoring (default: false until model trained)
ML_ENABLE=false

# Model file path (relative to project root)
ML_MODEL_PATH=.odavl/ml-models/trust-predictor-v1.json

# Fallback to heuristic if model fails to load
ML_HEURISTIC_FALLBACK=true

# -------------------------------------
# Data Collection Targets
# -------------------------------------
# TypeScript samples target
ML_TARGET_TYPESCRIPT=300000

# JavaScript samples target
ML_TARGET_JAVASCRIPT=200000

# Python samples target
ML_TARGET_PYTHON=400000

# Total target (sum of above)
ML_TARGET_TOTAL=900000

# -------------------------------------
# Training Hyperparameters
# -------------------------------------
# Number of training epochs
ML_EPOCHS=50

# Batch size for training
ML_BATCH_SIZE=32

# Learning rate (Adam optimizer)
ML_LEARNING_RATE=0.001

# Early stopping patience (epochs without improvement)
ML_EARLY_STOPPING_PATIENCE=10

# Dropout rate (regularization)
ML_DROPOUT_RATE=0.3

# Validation split ratio
ML_VALIDATION_SPLIT=0.15

# Test split ratio
ML_TEST_SPLIT=0.15

# -------------------------------------
# Prediction Thresholds
# -------------------------------------
# Minimum trust score for auto-approval
ML_AUTO_APPLY_THRESHOLD=0.85

# Minimum trust score for review suggestion
ML_REVIEW_THRESHOLD=0.65

# Minimum confidence for predictions
ML_CONFIDENCE_THRESHOLD=0.7

# Recipe blacklist threshold (below this = blacklisted)
ML_BLACKLIST_THRESHOLD=0.2

# -------------------------------------
# Feature Engineering
# -------------------------------------
# Maximum cyclomatic complexity for normalization
ML_MAX_COMPLEXITY=100

# Maximum lines changed for normalization
ML_MAX_LINES_CHANGED=100

# Maximum files modified for normalization
ML_MAX_FILES_MODIFIED=10

# Maximum days since failure for normalization
ML_MAX_DAYS_SINCE_FAILURE=30

# Maximum commits for maturity calculation
ML_MAX_COMMITS=1000

# Maximum GitHub stars for trust calculation
ML_MAX_STARS=10000

# -------------------------------------
# Data Collection Settings
# -------------------------------------
# Minimum repository stars filter
ML_MIN_REPO_STARS=100

# Maximum commits per repository
ML_MAX_COMMITS_PER_REPO=50

# Rate limit delay between requests (milliseconds)
ML_RATE_LIMIT_DELAY=1000

# Rate limit delay between files (milliseconds)
ML_FILE_RATE_LIMIT_DELAY=200

# Maximum retries for failed API requests
ML_MAX_RETRIES=3

# -------------------------------------
# Logging & Monitoring
# -------------------------------------
# Enable verbose logging
ML_VERBOSE=false

# Log file path
ML_LOG_PATH=.odavl/logs/ml-system.log

# Enable performance metrics
ML_METRICS_ENABLED=true

# Metrics output path
ML_METRICS_PATH=.odavl/metrics/ml-metrics.json

# -------------------------------------
# A/B Testing
# -------------------------------------
# Enable A/B testing (ML vs Legacy)
ML_AB_TESTING_ENABLED=false

# Percentage of traffic to ML (0-100)
ML_AB_TESTING_TRAFFIC=50

# Minimum samples for A/B test significance
ML_AB_TESTING_MIN_SAMPLES=1000

# -------------------------------------
# Production Settings
# -------------------------------------
# Environment (development, staging, production)
NODE_ENV=development

# Enable model caching
ML_CACHE_ENABLED=true

# Cache TTL (seconds)
ML_CACHE_TTL=3600

# Enable automatic model retraining
ML_AUTO_RETRAIN=false

# Minimum feedback samples before retraining
ML_RETRAIN_MIN_SAMPLES=10000

# -------------------------------------
# Error Handling
# -------------------------------------
# Fail gracefully on ML errors (fallback to heuristic)
ML_FAIL_GRACEFULLY=true

# Maximum prediction time (milliseconds)
ML_PREDICTION_TIMEOUT=5000

# Enable prediction result caching
ML_RESULT_CACHE_ENABLED=true
